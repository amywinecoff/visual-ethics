{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d19fe48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pylab as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import ImageFilter\n",
    "import cv2\n",
    "import itertools\n",
    "import random\n",
    "import keras\n",
    "import imutils\n",
    "from imutils import paths\n",
    "import os\n",
    "#from keras import optimizers\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential\n",
    "#from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose\n",
    "from keras import backend as K\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5adfc375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_image(img_path):\n",
    "    pil_im =PIL.Image.open(img_path).convert('L')\n",
    "    pil_im=pil_im.resize((105,105))\n",
    "    #imshow(np.asarray(pil_im))\n",
    "    return pil_im\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8785f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_image(pil_im):\n",
    "    # Adding Noise to image\n",
    "    img_array = np.asarray(pil_im)\n",
    "    mean = 0.0   # some constant\n",
    "    std = 5   # some constant (standard deviation)\n",
    "    noisy_img = img_array + np.random.normal(mean, std, img_array.shape)\n",
    "    noisy_img_clipped = np.clip(noisy_img, 0, 255)\n",
    "    noise_img = PIL.Image.fromarray(np.uint8(noisy_img_clipped)) # output\n",
    "    #imshow((noisy_img_clipped ).astype(np.uint8))\n",
    "    noise_img=noise_img.resize((105,105))\n",
    "    return noise_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ee5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_image(pil_im):\n",
    "    #Adding Blur to image \n",
    "    blur_img = pil_im.filter(ImageFilter.GaussianBlur(radius=3)) # ouput\n",
    "    #imshow(blur_img)\n",
    "    blur_img=blur_img.resize((105,105))\n",
    "    return blur_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6bd7fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_rotation(img):\n",
    "    \n",
    "    #img=cv2.imread(img_path,0)\n",
    "    rows, columns = img.shape\n",
    "\n",
    "    point1 = np.float32([[10, 10], [30, 10], [10, 30]])\n",
    "    point2 = np.float32([[20, 15], [40, 10], [20, 40]])\n",
    "\n",
    "    A = cv2.getAffineTransform(point1, point2)\n",
    "\n",
    "    output = cv2.warpAffine(img, A, (columns, rows))\n",
    "    affine_img = PIL.Image.fromarray(np.uint8(output)) # affine rotated output\n",
    "    #imshow(output)\n",
    "    affine_img=affine_img.resize((105,105))\n",
    "    return affine_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "032289a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_fill(image):\n",
    "    #image=cv2.imread(img_path,0)\n",
    "    laplacian = cv2.Laplacian(image,cv2.CV_64F)\n",
    "    laplacian = cv2.resize(laplacian, (105, 105))\n",
    "    return laplacian\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8538ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"font_patch/\"\n",
    "data=[]\n",
    "labels=[]\n",
    "imagePaths = sorted(list(paths.list_images(data_path)))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62858171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_label(label):\n",
    "    if label == 'Lato':\n",
    "        return 0\n",
    "    elif label == 'Raleway':\n",
    "        return 1\n",
    "    elif label == 'Roboto':\n",
    "        return 2\n",
    "    elif label == 'Sansation':\n",
    "        return 3\n",
    "    elif label == 'Walkway':\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45b66ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blur', 'noise', 'affine', 'gradient']\n"
     ]
    }
   ],
   "source": [
    "augument=[\"blur\",\"noise\",\"affine\",\"gradient\"]\n",
    "a=itertools.combinations(augument, 4)\n",
    "\n",
    "for i in list(a): \n",
    "    print(list(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83480425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for imagePath in imagePaths:\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    label = conv_label(label)\n",
    "    pil_img = pil_image(imagePath)\n",
    "    #imshow(pil_img)\n",
    "    \n",
    "    # Adding original image\n",
    "    org_img = img_to_array(pil_img)\n",
    "    #print(org_img.shape)\n",
    "    data.append(org_img)\n",
    "    labels.append(label)\n",
    "    \n",
    "    augument=[\"noise\",\"blur\",\"affine\",\"gradient\"]\n",
    "    for l in range(0,len(augument)):\n",
    "    \n",
    "        a=itertools.combinations(augument, l+1)\n",
    "\n",
    "        for i in list(a): \n",
    "            combinations=list(i)\n",
    "            print(len(combinations))\n",
    "            temp_img = pil_img\n",
    "            for j in combinations:\n",
    "            \n",
    "                if j == 'noise':\n",
    "                    # Adding Noise image\n",
    "                    temp_img = noise_image(temp_img)\n",
    "                    \n",
    "                elif j == 'blur':\n",
    "                    # Adding Blur image\n",
    "                    temp_img = blur_image(temp_img)\n",
    "                    #imshow(blur_img)\n",
    "                    \n",
    "    \n",
    "                elif j == 'affine':\n",
    "                    open_cv_affine = np.array(pil_img)\n",
    "                    # Adding affine rotation image\n",
    "                    temp_img = affine_rotation(open_cv_affine)\n",
    "\n",
    "                elif j == 'gradient':\n",
    "                    open_cv_gradient = np.array(pil_img)\n",
    "                    # Adding gradient image\n",
    "                    temp_img = gradient_fill(open_cv_gradient)\n",
    "  \n",
    "            temp_img = img_to_array(temp_img)\n",
    "            data.append(temp_img)\n",
    "            labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1644747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n"
     ]
    }
   ],
   "source": [
    "data = np.asarray(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "print(\"Success\")\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76a27070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=5)\n",
    "testY = to_categorical(testY, num_classes=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a7ab139",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "336ceaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K.set_image_dim_ordering('tf')\n",
    "K.set_image_data_format('channels_last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dd14e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(48, 48), activation='relu', input_shape=(105,105,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=(24, 24), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2DTranspose(128, (24,24), strides = (2,2), activation = 'relu', padding='same', kernel_initializer='uniform'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2DTranspose(64, (12,12), strides = (2,2), activation = 'relu', padding='same', kernel_initializer='uniform'))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "\n",
    "    #Cs Layers\n",
    "    model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(4096,activation='relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(2383,activation='relu'))\n",
    "\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d9205f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "model= create_model()\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9527aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
    "\n",
    "filepath=\"top_model.h5\"\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [early_stopping,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73ad2046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.2564 \n",
      "Epoch 1: val_loss improved from inf to 0.15864, saving model to top_model.h5\n",
      "4/4 [==============================] - 151s 38s/step - loss: 0.1601 - accuracy: 0.2564 - val_loss: 0.1586 - val_accuracy: 0.4167\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1492 - accuracy: 0.3632 \n",
      "Epoch 2: val_loss improved from 0.15864 to 0.15754, saving model to top_model.h5\n",
      "4/4 [==============================] - 171s 44s/step - loss: 0.1492 - accuracy: 0.3632 - val_loss: 0.1575 - val_accuracy: 0.4167\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1436 - accuracy: 0.4167 \n",
      "Epoch 3: val_loss did not improve from 0.15754\n",
      "4/4 [==============================] - 192s 49s/step - loss: 0.1436 - accuracy: 0.4167 - val_loss: 0.1577 - val_accuracy: 0.4167\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.4573 \n",
      "Epoch 4: val_loss improved from 0.15754 to 0.15733, saving model to top_model.h5\n",
      "4/4 [==============================] - 199s 48s/step - loss: 0.1349 - accuracy: 0.4573 - val_loss: 0.1573 - val_accuracy: 0.4679\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 0.5064 \n",
      "Epoch 5: val_loss improved from 0.15733 to 0.15719, saving model to top_model.h5\n",
      "4/4 [==============================] - 183s 45s/step - loss: 0.1232 - accuracy: 0.5064 - val_loss: 0.1572 - val_accuracy: 0.4872\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1116 - accuracy: 0.5684 \n",
      "Epoch 6: val_loss improved from 0.15719 to 0.15679, saving model to top_model.h5\n",
      "4/4 [==============================] - 215s 54s/step - loss: 0.1116 - accuracy: 0.5684 - val_loss: 0.1568 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.6047 \n",
      "Epoch 7: val_loss did not improve from 0.15679\n",
      "4/4 [==============================] - 213s 52s/step - loss: 0.0978 - accuracy: 0.6047 - val_loss: 0.1571 - val_accuracy: 0.5449\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.6731 \n",
      "Epoch 8: val_loss improved from 0.15679 to 0.15551, saving model to top_model.h5\n",
      "4/4 [==============================] - 220s 54s/step - loss: 0.0854 - accuracy: 0.6731 - val_loss: 0.1555 - val_accuracy: 0.5064\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.7030 \n",
      "Epoch 9: val_loss improved from 0.15551 to 0.15406, saving model to top_model.h5\n",
      "4/4 [==============================] - 232s 57s/step - loss: 0.0738 - accuracy: 0.7030 - val_loss: 0.1541 - val_accuracy: 0.5192\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.7436 \n",
      "Epoch 10: val_loss improved from 0.15406 to 0.15307, saving model to top_model.h5\n",
      "4/4 [==============================] - 211s 50s/step - loss: 0.0667 - accuracy: 0.7436 - val_loss: 0.1531 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.7350 \n",
      "Epoch 11: val_loss did not improve from 0.15307\n",
      "4/4 [==============================] - 196s 48s/step - loss: 0.0686 - accuracy: 0.7350 - val_loss: 0.1532 - val_accuracy: 0.4038\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0580 - accuracy: 0.7821 \n",
      "Epoch 12: val_loss did not improve from 0.15307\n",
      "4/4 [==============================] - 192s 47s/step - loss: 0.0580 - accuracy: 0.7821 - val_loss: 0.1567 - val_accuracy: 0.4808\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.8483   \n",
      "Epoch 13: val_loss did not improve from 0.15307\n",
      "4/4 [==============================] - 1304s 418s/step - loss: 0.0457 - accuracy: 0.8483 - val_loss: 0.1562 - val_accuracy: 0.4103\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 0.8590 \n",
      "Epoch 14: val_loss did not improve from 0.15307\n",
      "4/4 [==============================] - 149s 36s/step - loss: 0.0420 - accuracy: 0.8590 - val_loss: 0.1612 - val_accuracy: 0.4615\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 0.8526 \n",
      "Epoch 15: val_loss did not improve from 0.15307\n",
      "4/4 [==============================] - 148s 37s/step - loss: 0.0407 - accuracy: 0.8526 - val_loss: 0.1576 - val_accuracy: 0.3910\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.8675 \n",
      "Epoch 16: val_loss did not improve from 0.15307\n",
      "4/4 [==============================] - 155s 39s/step - loss: 0.0374 - accuracy: 0.8675 - val_loss: 0.1590 - val_accuracy: 0.5385\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.8932 \n",
      "Epoch 17: val_loss did not improve from 0.15307\n",
      "4/4 [==============================] - 167s 41s/step - loss: 0.0322 - accuracy: 0.8932 - val_loss: 0.1616 - val_accuracy: 0.4038\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.8953 \n",
      "Epoch 18: val_loss did not improve from 0.15307\n",
      "4/4 [==============================] - 169s 41s/step - loss: 0.0325 - accuracy: 0.8953 - val_loss: 0.1732 - val_accuracy: 0.5064\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.7799 \n",
      "Epoch 19: val_loss did not improve from 0.15307\n",
      "4/4 [==============================] - 185s 46s/step - loss: 0.0604 - accuracy: 0.7799 - val_loss: 0.1869 - val_accuracy: 0.6154\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.6923 \n",
      "Epoch 20: val_loss did not improve from 0.15307\n",
      "4/4 [==============================] - 189s 46s/step - loss: 0.0760 - accuracy: 0.6923 - val_loss: 0.1760 - val_accuracy: 0.3654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd070932af0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY,shuffle=True,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(testX, testY),callbacks=callbacks_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1f0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e766e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('top_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2828ba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(testX, testY, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9b269",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path=\"sample.jpg\"\n",
    "pil_im =PIL.Image.open(img_path).convert('L')\n",
    "pil_im=blur_img(pil_im)\n",
    "org_img = img_to_array(pil_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607fd62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_conv_label(label):\n",
    "    if label == 0 :\n",
    "        return 'Lato'\n",
    "    elif label == 1:\n",
    "        return 'Raleway'\n",
    "    elif label == 2 :\n",
    "        return 'Roboto'\n",
    "    elif label == 3 :\n",
    "        return 'Sansation'\n",
    "    elif label == 4:\n",
    "        return 'Walkway'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "data.append(org_img)\n",
    "data = np.asarray(data, dtype=\"float\") / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6378e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5889ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = rev_conv_label(int(y[0]))\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(pil_im, interpolation='nearest', cmap=cm.gray)\n",
    "ax.text(5, 5, label , bbox={'facecolor': 'white', 'pad': 10})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
